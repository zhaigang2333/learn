{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round_price_data1.csv是经过处理后的周围房屋房价，取了16个周围房价，取16个是为了好卷积\n",
    "data = pd.read_csv('round_price_data1.csv')\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(type(data.index),data.index),range of index\n",
    "#data是dataFrame格式的数据，而处理卷积的数据要求格式为np.narry,因此需要把数据转换出来，有没有更好的方法暂时没找\n",
    "data_features=[] #特征数组\n",
    "data_lables=[] #特征对应的标签\n",
    "\n",
    "\n",
    "#data.iloc[i]=<class 'pandas.core.series.Series'> 取dataFrame行数据\n",
    "\n",
    "for i in data.index:\n",
    "    data_features.append([])  #为了形成二维数组[[],[],[]...]\n",
    "    for index,v in data.iloc[i].items():\n",
    "        if(index=='price_real'):\n",
    "            data_lables.append(v)  \n",
    "        else:\n",
    "            data_features[i].append(v)\n",
    "#print(data_features,data_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.179   0.179   0.179   ... 0.179   0.179   0.179  ]\n",
      " [0.308   0.308   0.308   ... 0.308   0.308   0.308  ]\n",
      " [0.41    0.47    0.48    ... 0.553   0.553   0.553  ]\n",
      " ...\n",
      " [0.22    0.28    0.32    ... 0.285   0.285   0.285  ]\n",
      " [0.96    0.79    0.65    ... 0.78275 0.78275 0.78275]\n",
      " [0.81    0.81    0.81    ... 0.81    0.81    0.81   ]]\n"
     ]
    }
   ],
   "source": [
    "#两种方式进行归一化，第一种用sklearn自带方法，是根据每个元素值在平均数的浮动来进行归一化，由于此种卷积出来的效果不好舍弃了\n",
    "#第二种直接除以1kw\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "# data_features=scaler.fit_transform(data_features)\n",
    "# data_lables=scaler.fit_transform(data_lables)\n",
    "data_features=np.array(data_features)/10000000\n",
    "data_lables=np.array(data_lables)/10000000\n",
    "print(data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'data': array([[0.179  , 0.179  , 0.179  , ..., 0.179  , 0.179  , 0.179  ],\n",
      "       [0.308  , 0.308  , 0.308  , ..., 0.308  , 0.308  , 0.308  ],\n",
      "       [0.41   , 0.47   , 0.48   , ..., 0.553  , 0.553  , 0.553  ],\n",
      "       ...,\n",
      "       [0.22   , 0.28   , 0.32   , ..., 0.285  , 0.285  , 0.285  ],\n",
      "       [0.96   , 0.79   , 0.65   , ..., 0.78275, 0.78275, 0.78275],\n",
      "       [0.81   , 0.81   , 0.81   , ..., 0.81   , 0.81   , 0.81   ]]), b'lables': array([0.179, 0.308, 0.41 , ..., 0.32 , 0.665, 0.81 ])}\n"
     ]
    }
   ],
   "source": [
    "#处理原始数据\n",
    "data_obj={\n",
    "    b'data':data_features,\n",
    "    b'lables':data_lables\n",
    "}\n",
    "print(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# 定义数据格式 4*4*1，np.zeros创建空矩阵\n",
    "\n",
    "blank_image= np.zeros((len(data_obj[b'data']),4,4,1), np.float64) \n",
    "print(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向空矩阵中填充数据\n",
    "#print(np.array(data_obj[b'data'][1][0:16]).reshape(4,4))\n",
    "#print(blank_image[1][0:1,0:1,0:1])\n",
    "# print(blank_image[1][0:2,0:2])\n",
    "# print(blank_image[1][0:2,0:2,0])\n",
    "#串联所有通道为一维数组，blank_image[i][:,:,0]，取第1个通道的全部值\n",
    "\n",
    "for i in range(len(data_obj[b'data'])):\n",
    "    blank_image[i][:,:,0]=np.array(data_obj[b'data'][i][0:16]).reshape(4,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'data': array([[0.179  , 0.179  , 0.179  , ..., 0.179  , 0.179  , 0.179  ],\n",
      "       [0.308  , 0.308  , 0.308  , ..., 0.308  , 0.308  , 0.308  ],\n",
      "       [0.41   , 0.47   , 0.48   , ..., 0.553  , 0.553  , 0.553  ],\n",
      "       ...,\n",
      "       [0.22   , 0.28   , 0.32   , ..., 0.285  , 0.285  , 0.285  ],\n",
      "       [0.96   , 0.79   , 0.65   , ..., 0.78275, 0.78275, 0.78275],\n",
      "       [0.81   , 0.81   , 0.81   , ..., 0.81   , 0.81   , 0.81   ]]), b'lables': array([0.179, 0.308, 0.41 , ..., 0.32 , 0.665, 0.81 ])}\n"
     ]
    }
   ],
   "source": [
    "data_obj[b'lables']=np.array(data_obj[b'lables'])\n",
    "print(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "1901\n",
      "2100\n",
      "1901\n"
     ]
    }
   ],
   "source": [
    "#划分训练测试集\n",
    "X_train=blank_image[:2100]\n",
    "X_test=blank_image[2100:]\n",
    "y_train=data_obj[b'lables'][:2100]\n",
    "y_test=data_obj[b'lables'][2100:]\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(X_test, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2100, 4, 4, 1)\n",
      "2100 train samples\n",
      "1901 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 4, 1)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(4, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(1, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        #layers.Dropout(0.5),#避免过拟合\n",
    "        layers.Dense(1,activation='linear')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 4)           580       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 1)           37        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 794\n",
      "Trainable params: 794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.0026 - val_loss: 0.0624 - val_accuracy: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f024fd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1,verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.014009148813784122\n",
      "Test accuracy: 0.003682272508740425\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5141655 ]\n",
      " [0.47961882]\n",
      " [0.6933762 ]\n",
      " ...\n",
      " [0.27971557]\n",
      " [0.7742141 ]\n",
      " [0.81685627]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52  0.6   0.59  ... 0.32  0.665 0.81 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'conv2d/Relu:0' shape=(None, 4, 4, 16) dtype=float32>, <tf.Tensor 'conv2d_1/Relu:0' shape=(None, 4, 4, 4) dtype=float32>, <tf.Tensor 'conv2d_2/Relu:0' shape=(None, 4, 4, 1) dtype=float32>, <tf.Tensor 'flatten/Reshape:0' shape=(None, 16) dtype=float32>, <tf.Tensor 'dense/BiasAdd:0' shape=(None, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x13ef87780>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处为了获得纯卷积结果，但是这个卷积是不纯的，因为经过了很多次迭代，不是一次卷积的结果，但是考虑到精确度不足4%，忽略了，换成一次迭代也是一样：（\n",
    "#这个设计有点意思，把model拿过来再做一次，只为了得到某一层的卷积结果\n",
    "layer_model =tf.keras.Model(inputs=model.input, outputs=model.layers[4].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得全部输入的卷积结果\n",
    "feature=layer_model.predict(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "4001\n",
      "[[-9481259.01739289]\n",
      " [-5213480.32584452]\n",
      " [ 3436737.55764033]\n",
      " ...\n",
      " [-5948475.31491104]\n",
      " [10070568.58627526]\n",
      " [11451935.76584956]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "print(type(feature))\n",
    "print(len(feature))\n",
    "\n",
    "#此处解释了之前归一化为什么不用fit_transform，因为卷积结果还要还原\n",
    "feature=feature*10000000\n",
    "print(feature)\n",
    "\n",
    "#再进行归一化，因为用XGboost方法训练的时候是用fit_transform归一化的\n",
    "scaler = preprocessing.StandardScaler()\n",
    "feature=scaler.fit_transform(feature)\n",
    "\n",
    "\n",
    "#numpy.ndarray转换array，再利用array转换成dataFrame，存在.csv文件，是在愚钝只能用此蠢方法了\n",
    "data=[]\n",
    "for i in range(len(feature)):\n",
    "    data.append([])\n",
    "    data[i].append(feature[i][0])\n",
    "#print(data)\n",
    "dff=pd.DataFrame()\n",
    "dd=dff.append(data)\n",
    "dd.to_csv('round_price_predict.csv',index=False)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#另外一种方法获得卷积结果，殊途同归\n",
    "\n",
    "from keras import backend as K\n",
    "def get_output_function(model,output_layer_index):\n",
    "    vector_funcrion=K.function([model.layers[0].input],[model.layers[output_layer_index].output])\n",
    "\n",
    "    def inner(input_data):\n",
    "\n",
    "        vector=vector_funcrion([input_data])[0]\n",
    "\n",
    "        return vector\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature=get_output_function(model,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=get_feature(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5141655 ]\n",
      " [0.47961882]\n",
      " [0.6933762 ]\n",
      " ...\n",
      " [0.27971557]\n",
      " [0.7742141 ]\n",
      " [0.81685627]]\n"
     ]
    }
   ],
   "source": [
    "print(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
