{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round_price_data1.csv是经过处理后的周围房屋房价，取了16个周围房价，取16个是为了好卷积\n",
    "data = pd.read_csv('round_price_data1.csv')\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price_real           0           1             2             3  \\\n",
      "0      1790000.0   1790000.0   1790000.0  1.790000e+06  1.790000e+06   \n",
      "1      3080000.0   3080000.0   3080000.0  3.080000e+06  3.080000e+06   \n",
      "2      4100000.0   4100000.0   4700000.0  4.800000e+06  4.800000e+06   \n",
      "3      7900000.0   7900000.0   7700000.0  7.800000e+06  7.100000e+06   \n",
      "4      7500000.0   7500000.0   6800000.0  8.000000e+06  7.000000e+06   \n",
      "5      4200000.0   4200000.0   4800000.0  4.360000e+06  4.700000e+06   \n",
      "6      4800000.0   4200000.0   4800000.0  4.360000e+06  4.700000e+06   \n",
      "7      3500000.0   3500000.0   2700000.0  2.480000e+06  3.100000e+06   \n",
      "8      4850000.0   4850000.0   5200000.0  5.400000e+06  4.200000e+06   \n",
      "9      4750000.0   4750000.0   8680000.0  4.500000e+06  4.350000e+06   \n",
      "10     4150000.0   4150000.0   3650000.0  3.300000e+06  3.650000e+06   \n",
      "11     6980000.0   6980000.0   6450000.0  7.200000e+06  6.900000e+06   \n",
      "12    13380000.0  13380000.0  11000000.0  1.480000e+07  1.314000e+07   \n",
      "13    11000000.0  13380000.0  11000000.0  1.480000e+07  1.254500e+07   \n",
      "14     9200000.0   9200000.0   7800000.0  9.000000e+06  1.110000e+07   \n",
      "15    12980000.0  12980000.0  12300000.0  1.600000e+07  1.300000e+07   \n",
      "16     4200000.0   4200000.0   4200000.0  4.200000e+06  4.200000e+06   \n",
      "17     3650000.0   3650000.0   3600000.0  4.950000e+06  3.850000e+06   \n",
      "18     3350000.0   3350000.0   4600000.0  4.200000e+06  4.700000e+06   \n",
      "19     8000000.0   8000000.0   8300000.0  8.700000e+06  7.600000e+06   \n",
      "20     4000000.0   4000000.0   3450000.0  4.150000e+06  4.960000e+06   \n",
      "21     4970000.0   4970000.0   3350000.0  2.850000e+06  2.250000e+06   \n",
      "22     4700000.0   4100000.0   4700000.0  4.800000e+06  4.800000e+06   \n",
      "23     8300000.0   8000000.0   8300000.0  8.700000e+06  7.600000e+06   \n",
      "24     2700000.0   2700000.0   2880000.0  3.000000e+06  3.100000e+06   \n",
      "25     7300000.0   7300000.0   7800000.0  8.000000e+06  8.300000e+06   \n",
      "26     8680000.0   4750000.0   8680000.0  4.500000e+06  4.350000e+06   \n",
      "27     2800000.0   2800000.0   2560000.0  3.550000e+06  3.550000e+06   \n",
      "28     4800000.0   4800000.0   4290000.0  4.250000e+06  4.250000e+06   \n",
      "29     9500000.0   9500000.0   9600000.0  9.600000e+06  9.550000e+06   \n",
      "...          ...         ...         ...           ...           ...   \n",
      "3971   9500000.0   1950000.0   1790000.0  1.680000e+06  2.400000e+06   \n",
      "3972   6450000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3973   9280000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3974   5700000.0   7200000.0   5700000.0  6.200000e+06  6.200000e+06   \n",
      "3975   9800000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3976  11500000.0  11800000.0   8220000.0  1.150000e+07  1.400000e+07   \n",
      "3977   9200000.0   2280000.0   2450000.0  2.500000e+06  1.950000e+06   \n",
      "3978   9000000.0   1950000.0   1790000.0  1.680000e+06  2.400000e+06   \n",
      "3979   2550000.0   2500000.0   3530000.0  4.950000e+06  2.550000e+06   \n",
      "3980   6050000.0   6000000.0   6050000.0  6.350000e+06  5.400000e+06   \n",
      "3981   6350000.0   6000000.0   6050000.0  6.350000e+06  5.400000e+06   \n",
      "3982  14000000.0  11800000.0   8220000.0  1.150000e+07  1.400000e+07   \n",
      "3983   5750000.0   3600000.0   6300000.0  2.700000e+06  3.250000e+06   \n",
      "3984  11000000.0  11800000.0   8220000.0  1.150000e+07  1.400000e+07   \n",
      "3985   5600000.0   5600000.0   6900000.0  6.650000e+06  5.600000e+06   \n",
      "3986   7900000.0   1950000.0   1790000.0  1.680000e+06  2.400000e+06   \n",
      "3987  12200000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3988  17880000.0  17880000.0  17880000.0  1.788000e+07  1.788000e+07   \n",
      "3989   5900000.0   5900000.0   5900000.0  5.900000e+06  5.900000e+06   \n",
      "3990   6900000.0   8500000.0   6900000.0  7.433333e+06  7.433333e+06   \n",
      "3991   5400000.0   6000000.0   6050000.0  6.350000e+06  5.400000e+06   \n",
      "3992   8300000.0   1950000.0   1790000.0  1.680000e+06  2.400000e+06   \n",
      "3993   9500000.0  10600000.0   8300000.0  9.500000e+06  9.475000e+06   \n",
      "3994   4500000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3995   6300000.0   3600000.0   6300000.0  2.700000e+06  3.250000e+06   \n",
      "3996   4500000.0   4600000.0   5990000.0  4.500000e+06  4.897500e+06   \n",
      "3997   8000000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "3998   3200000.0   2200000.0   2800000.0  3.200000e+06  2.850000e+06   \n",
      "3999   6650000.0   9600000.0   7900000.0  6.500000e+06  6.400000e+06   \n",
      "4000   8100000.0   8100000.0   8100000.0  8.100000e+06  8.100000e+06   \n",
      "\n",
      "                 4             5             6             7             8  \\\n",
      "0     1.790000e+06  1.790000e+06  1.790000e+06  1.790000e+06  1.790000e+06   \n",
      "1     3.080000e+06  3.080000e+06  3.080000e+06  3.080000e+06  3.080000e+06   \n",
      "2     6.000000e+06  4.200000e+06  6.300000e+06  8.800000e+06  7.500000e+06   \n",
      "3     7.600000e+06  9.150000e+06  7.878571e+06  7.878571e+06  7.878571e+06   \n",
      "4     1.200000e+07  9.000000e+06  4.380000e+06  4.200000e+06  7.375556e+06   \n",
      "5     6.350000e+06  6.500000e+06  5.900000e+06  5.126250e+06  5.126250e+06   \n",
      "6     6.350000e+06  6.500000e+06  5.900000e+06  5.201250e+06  5.201250e+06   \n",
      "7     4.250000e+06  3.300000e+06  3.280000e+06  2.600000e+06  2.880000e+06   \n",
      "8     4.900000e+06  4.900000e+06  4.900000e+06  4.900000e+06  4.900000e+06   \n",
      "9     8.120000e+06  5.858333e+06  5.858333e+06  5.858333e+06  5.858333e+06   \n",
      "10    3.550000e+06  3.180000e+06  3.280000e+06  3.250000e+06  3.850000e+06   \n",
      "11    6.902000e+06  6.902000e+06  6.902000e+06  6.902000e+06  6.902000e+06   \n",
      "12    1.314000e+07  1.314000e+07  1.314000e+07  1.314000e+07  1.314000e+07   \n",
      "13    1.254500e+07  1.254500e+07  1.254500e+07  1.254500e+07  1.254500e+07   \n",
      "14    1.250000e+07  7.050000e+06  6.900000e+06  9.093750e+06  9.093750e+06   \n",
      "15    1.345200e+07  1.345200e+07  1.345200e+07  1.345200e+07  1.345200e+07   \n",
      "16    4.200000e+06  4.200000e+06  4.200000e+06  4.200000e+06  4.200000e+06   \n",
      "17    2.700000e+06  3.700000e+06  3.850000e+06  4.050000e+06  4.450000e+06   \n",
      "18    5.000000e+06  4.200000e+06  7.200000e+06  5.300000e+06  4.860000e+06   \n",
      "19    5.800000e+06  7.733333e+06  7.733333e+06  7.733333e+06  7.733333e+06   \n",
      "20    4.800000e+06  4.900000e+06  3.300000e+06  3.850000e+06  4.200000e+06   \n",
      "21    2.250000e+06  3.500000e+06  3.300000e+06  3.430000e+06  3.430000e+06   \n",
      "22    6.000000e+06  4.200000e+06  6.300000e+06  8.800000e+06  7.500000e+06   \n",
      "23    5.800000e+06  7.783333e+06  7.783333e+06  7.783333e+06  7.783333e+06   \n",
      "24    2.850000e+06  3.800000e+06  3.900000e+06  3.116250e+06  3.116250e+06   \n",
      "25    7.250000e+06  6.200000e+06  7.450000e+06  7.450000e+06  7.450000e+06   \n",
      "26    8.120000e+06  6.513333e+06  6.513333e+06  6.513333e+06  6.513333e+06   \n",
      "27    4.050000e+06  3.650000e+06  3.700000e+06  3.780000e+06  3.700000e+06   \n",
      "28    4.450000e+06  3.980000e+06  3.200000e+06  3.800000e+06  2.600000e+06   \n",
      "29    9.550000e+06  9.550000e+06  9.550000e+06  9.550000e+06  9.550000e+06   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "3971  1.650000e+06  2.200000e+06  9.000000e+06  8.400000e+06  1.000000e+07   \n",
      "3972  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3973  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3974  6.200000e+06  6.200000e+06  6.200000e+06  6.200000e+06  6.200000e+06   \n",
      "3975  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3976  1.100000e+07  1.133667e+07  1.133667e+07  1.133667e+07  1.133667e+07   \n",
      "3977  3.900000e+06  8.100000e+06  9.200000e+06  4.947500e+06  4.947500e+06   \n",
      "3978  1.650000e+06  2.200000e+06  9.000000e+06  8.400000e+06  1.000000e+07   \n",
      "3979  3.216000e+06  3.216000e+06  3.216000e+06  3.216000e+06  3.216000e+06   \n",
      "3980  5.970000e+06  5.970000e+06  5.970000e+06  5.970000e+06  5.970000e+06   \n",
      "3981  6.030000e+06  6.030000e+06  6.030000e+06  6.030000e+06  6.030000e+06   \n",
      "3982  1.100000e+07  1.175333e+07  1.175333e+07  1.175333e+07  1.175333e+07   \n",
      "3983  3.350000e+06  5.750000e+06  6.300000e+06  4.625000e+06  4.625000e+06   \n",
      "3984  1.100000e+07  1.125333e+07  1.125333e+07  1.125333e+07  1.125333e+07   \n",
      "3985  6.070000e+06  6.070000e+06  6.070000e+06  6.070000e+06  6.070000e+06   \n",
      "3986  1.650000e+06  2.200000e+06  9.000000e+06  8.400000e+06  1.000000e+07   \n",
      "3987  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3988  1.788000e+07  1.788000e+07  1.788000e+07  1.788000e+07  1.788000e+07   \n",
      "3989  5.900000e+06  5.900000e+06  5.900000e+06  5.900000e+06  5.900000e+06   \n",
      "3990  7.433333e+06  7.433333e+06  7.433333e+06  7.433333e+06  7.433333e+06   \n",
      "3991  5.840000e+06  5.840000e+06  5.840000e+06  5.840000e+06  5.840000e+06   \n",
      "3992  1.650000e+06  2.200000e+06  9.000000e+06  8.400000e+06  1.000000e+07   \n",
      "3993  9.475000e+06  9.475000e+06  9.475000e+06  9.475000e+06  9.475000e+06   \n",
      "3994  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3995  3.350000e+06  5.750000e+06  6.300000e+06  4.693750e+06  4.693750e+06   \n",
      "3996  4.897500e+06  4.897500e+06  4.897500e+06  4.897500e+06  4.897500e+06   \n",
      "3997  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "3998  2.850000e+06  2.850000e+06  2.850000e+06  2.850000e+06  2.850000e+06   \n",
      "3999  6.450000e+06  9.280000e+06  9.800000e+06  1.220000e+07  4.500000e+06   \n",
      "4000  8.100000e+06  8.100000e+06  8.100000e+06  8.100000e+06  8.100000e+06   \n",
      "\n",
      "                 9            10            11            12            13  \\\n",
      "0     1.790000e+06  1.790000e+06  1.790000e+06  1.790000e+06  1.790000e+06   \n",
      "1     3.080000e+06  3.080000e+06  3.080000e+06  3.080000e+06  3.080000e+06   \n",
      "2     5.530000e+06  5.530000e+06  5.530000e+06  5.530000e+06  5.530000e+06   \n",
      "3     7.878571e+06  7.878571e+06  7.878571e+06  7.878571e+06  7.878571e+06   \n",
      "4     7.375556e+06  7.375556e+06  7.375556e+06  7.375556e+06  7.375556e+06   \n",
      "5     5.126250e+06  5.126250e+06  5.126250e+06  5.126250e+06  5.126250e+06   \n",
      "6     5.201250e+06  5.201250e+06  5.201250e+06  5.201250e+06  5.201250e+06   \n",
      "7     4.600000e+06  4.600000e+06  2.750000e+06  4.600000e+06  2.780000e+06   \n",
      "8     4.900000e+06  4.900000e+06  4.900000e+06  4.900000e+06  4.900000e+06   \n",
      "9     5.858333e+06  5.858333e+06  5.858333e+06  5.858333e+06  5.858333e+06   \n",
      "10    3.300000e+06  3.250000e+06  3.300000e+06  3.950000e+06  2.850000e+06   \n",
      "11    6.902000e+06  6.902000e+06  6.902000e+06  6.902000e+06  6.902000e+06   \n",
      "12    1.314000e+07  1.314000e+07  1.314000e+07  1.314000e+07  1.314000e+07   \n",
      "13    1.254500e+07  1.254500e+07  1.254500e+07  1.254500e+07  1.254500e+07   \n",
      "14    9.093750e+06  9.093750e+06  9.093750e+06  9.093750e+06  9.093750e+06   \n",
      "15    1.345200e+07  1.345200e+07  1.345200e+07  1.345200e+07  1.345200e+07   \n",
      "16    4.200000e+06  4.200000e+06  4.200000e+06  4.200000e+06  4.200000e+06   \n",
      "17    3.845000e+06  3.845000e+06  3.845000e+06  3.845000e+06  3.845000e+06   \n",
      "18    6.680000e+06  7.600000e+06  5.086667e+06  5.086667e+06  5.086667e+06   \n",
      "19    7.733333e+06  7.733333e+06  7.733333e+06  7.733333e+06  7.733333e+06   \n",
      "20    3.650000e+06  3.450000e+06  4.600000e+06  3.800000e+06  3.650000e+06   \n",
      "21    3.430000e+06  3.430000e+06  3.430000e+06  3.430000e+06  3.430000e+06   \n",
      "22    5.590000e+06  5.590000e+06  5.590000e+06  5.590000e+06  5.590000e+06   \n",
      "23    7.783333e+06  7.783333e+06  7.783333e+06  7.783333e+06  7.783333e+06   \n",
      "24    3.116250e+06  3.116250e+06  3.116250e+06  3.116250e+06  3.116250e+06   \n",
      "25    7.450000e+06  7.450000e+06  7.450000e+06  7.450000e+06  7.450000e+06   \n",
      "26    6.513333e+06  6.513333e+06  6.513333e+06  6.513333e+06  6.513333e+06   \n",
      "27    2.950000e+06  3.600000e+06  8.750000e+06  2.950000e+06  4.320000e+06   \n",
      "28    3.400000e+06  4.000000e+06  2.480000e+06  4.150000e+06  2.300000e+06   \n",
      "29    9.550000e+06  9.550000e+06  9.550000e+06  9.550000e+06  9.550000e+06   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "3971  8.700000e+06  9.500000e+06  9.000000e+06  7.900000e+06  8.300000e+06   \n",
      "3972  8.000000e+06  6.650000e+06  7.810833e+06  7.810833e+06  7.810833e+06   \n",
      "3973  8.000000e+06  6.650000e+06  8.046667e+06  8.046667e+06  8.046667e+06   \n",
      "3974  6.200000e+06  6.200000e+06  6.200000e+06  6.200000e+06  6.200000e+06   \n",
      "3975  8.000000e+06  6.650000e+06  8.090000e+06  8.090000e+06  8.090000e+06   \n",
      "3976  1.133667e+07  1.133667e+07  1.133667e+07  1.133667e+07  1.133667e+07   \n",
      "3977  4.947500e+06  4.947500e+06  4.947500e+06  4.947500e+06  4.947500e+06   \n",
      "3978  8.700000e+06  9.500000e+06  9.000000e+06  7.900000e+06  8.300000e+06   \n",
      "3979  3.216000e+06  3.216000e+06  3.216000e+06  3.216000e+06  3.216000e+06   \n",
      "3980  5.970000e+06  5.970000e+06  5.970000e+06  5.970000e+06  5.970000e+06   \n",
      "3981  6.030000e+06  6.030000e+06  6.030000e+06  6.030000e+06  6.030000e+06   \n",
      "3982  1.175333e+07  1.175333e+07  1.175333e+07  1.175333e+07  1.175333e+07   \n",
      "3983  4.625000e+06  4.625000e+06  4.625000e+06  4.625000e+06  4.625000e+06   \n",
      "3984  1.125333e+07  1.125333e+07  1.125333e+07  1.125333e+07  1.125333e+07   \n",
      "3985  6.070000e+06  6.070000e+06  6.070000e+06  6.070000e+06  6.070000e+06   \n",
      "3986  8.700000e+06  9.500000e+06  9.000000e+06  7.900000e+06  8.300000e+06   \n",
      "3987  8.000000e+06  6.650000e+06  8.290000e+06  8.290000e+06  8.290000e+06   \n",
      "3988  1.788000e+07  1.788000e+07  1.788000e+07  1.788000e+07  1.788000e+07   \n",
      "3989  5.900000e+06  5.900000e+06  5.900000e+06  5.900000e+06  5.900000e+06   \n",
      "3990  7.433333e+06  7.433333e+06  7.433333e+06  7.433333e+06  7.433333e+06   \n",
      "3991  5.840000e+06  5.840000e+06  5.840000e+06  5.840000e+06  5.840000e+06   \n",
      "3992  8.700000e+06  9.500000e+06  9.000000e+06  7.900000e+06  8.300000e+06   \n",
      "3993  9.475000e+06  9.475000e+06  9.475000e+06  9.475000e+06  9.475000e+06   \n",
      "3994  8.000000e+06  6.650000e+06  7.648333e+06  7.648333e+06  7.648333e+06   \n",
      "3995  4.693750e+06  4.693750e+06  4.693750e+06  4.693750e+06  4.693750e+06   \n",
      "3996  4.897500e+06  4.897500e+06  4.897500e+06  4.897500e+06  4.897500e+06   \n",
      "3997  8.000000e+06  6.650000e+06  7.940000e+06  7.940000e+06  7.940000e+06   \n",
      "3998  2.850000e+06  2.850000e+06  2.850000e+06  2.850000e+06  2.850000e+06   \n",
      "3999  8.000000e+06  6.650000e+06  7.827500e+06  7.827500e+06  7.827500e+06   \n",
      "4000  8.100000e+06  8.100000e+06  8.100000e+06  8.100000e+06  8.100000e+06   \n",
      "\n",
      "                14            15  \n",
      "0     1.790000e+06  1.790000e+06  \n",
      "1     3.080000e+06  3.080000e+06  \n",
      "2     5.530000e+06  5.530000e+06  \n",
      "3     7.878571e+06  7.878571e+06  \n",
      "4     7.375556e+06  7.375556e+06  \n",
      "5     5.126250e+06  5.126250e+06  \n",
      "6     5.201250e+06  5.201250e+06  \n",
      "7     3.500000e+06  4.500000e+06  \n",
      "8     4.900000e+06  4.900000e+06  \n",
      "9     5.858333e+06  5.858333e+06  \n",
      "10    3.400000e+06  3.200000e+06  \n",
      "11    6.902000e+06  6.902000e+06  \n",
      "12    1.314000e+07  1.314000e+07  \n",
      "13    1.254500e+07  1.254500e+07  \n",
      "14    9.093750e+06  9.093750e+06  \n",
      "15    1.345200e+07  1.345200e+07  \n",
      "16    4.200000e+06  4.200000e+06  \n",
      "17    3.845000e+06  3.845000e+06  \n",
      "18    5.086667e+06  5.086667e+06  \n",
      "19    7.733333e+06  7.733333e+06  \n",
      "20    3.600000e+06  4.022500e+06  \n",
      "21    3.430000e+06  3.430000e+06  \n",
      "22    5.590000e+06  5.590000e+06  \n",
      "23    7.783333e+06  7.783333e+06  \n",
      "24    3.116250e+06  3.116250e+06  \n",
      "25    7.450000e+06  7.450000e+06  \n",
      "26    6.513333e+06  6.513333e+06  \n",
      "27    3.780667e+06  3.780667e+06  \n",
      "28    2.490000e+06  2.750000e+06  \n",
      "29    9.550000e+06  9.550000e+06  \n",
      "...            ...           ...  \n",
      "3971  6.131333e+06  6.131333e+06  \n",
      "3972  7.810833e+06  7.810833e+06  \n",
      "3973  8.046667e+06  8.046667e+06  \n",
      "3974  6.200000e+06  6.200000e+06  \n",
      "3975  8.090000e+06  8.090000e+06  \n",
      "3976  1.133667e+07  1.133667e+07  \n",
      "3977  4.947500e+06  4.947500e+06  \n",
      "3978  6.098000e+06  6.098000e+06  \n",
      "3979  3.216000e+06  3.216000e+06  \n",
      "3980  5.970000e+06  5.970000e+06  \n",
      "3981  6.030000e+06  6.030000e+06  \n",
      "3982  1.175333e+07  1.175333e+07  \n",
      "3983  4.625000e+06  4.625000e+06  \n",
      "3984  1.125333e+07  1.125333e+07  \n",
      "3985  6.070000e+06  6.070000e+06  \n",
      "3986  6.024667e+06  6.024667e+06  \n",
      "3987  8.290000e+06  8.290000e+06  \n",
      "3988  1.788000e+07  1.788000e+07  \n",
      "3989  5.900000e+06  5.900000e+06  \n",
      "3990  7.433333e+06  7.433333e+06  \n",
      "3991  5.840000e+06  5.840000e+06  \n",
      "3992  6.051333e+06  6.051333e+06  \n",
      "3993  9.475000e+06  9.475000e+06  \n",
      "3994  7.648333e+06  7.648333e+06  \n",
      "3995  4.693750e+06  4.693750e+06  \n",
      "3996  4.897500e+06  4.897500e+06  \n",
      "3997  7.940000e+06  7.940000e+06  \n",
      "3998  2.850000e+06  2.850000e+06  \n",
      "3999  7.827500e+06  7.827500e+06  \n",
      "4000  8.100000e+06  8.100000e+06  \n",
      "\n",
      "[4001 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(type(data.index),data.index),range of index\n",
    "#data是dataFrame格式的数据，而处理卷积的数据要求格式为np.narry,因此需要把数据转换出来，有没有更好的方法暂时没找\n",
    "data_features=[] #特征数组\n",
    "data_lables=[] #特征对应的标签\n",
    "\n",
    "\n",
    "#data.iloc[i]=<class 'pandas.core.series.Series'> 取dataFrame行数据\n",
    "\n",
    "for i in data.index:\n",
    "    data_features.append([])  #为了形成二维数组[[],[],[]...]\n",
    "    for index,v in data.iloc[i].items():\n",
    "        if(index=='price_real'):\n",
    "            data_lables.append(v)  \n",
    "        else:\n",
    "            data_features[i].append(v)\n",
    "#print(data_features,data_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.179   0.179   0.179   ... 0.179   0.179   0.179  ]\n",
      " [0.308   0.308   0.308   ... 0.308   0.308   0.308  ]\n",
      " [0.41    0.47    0.48    ... 0.553   0.553   0.553  ]\n",
      " ...\n",
      " [0.22    0.28    0.32    ... 0.285   0.285   0.285  ]\n",
      " [0.96    0.79    0.65    ... 0.78275 0.78275 0.78275]\n",
      " [0.81    0.81    0.81    ... 0.81    0.81    0.81   ]]\n"
     ]
    }
   ],
   "source": [
    "#两种方式进行归一化，第一种用sklearn自带方法，是根据每个元素值在平均数的浮动来进行归一化，由于此种卷积出来的效果不好舍弃了\n",
    "#第二种直接除以1kw\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "# data_features=scaler.fit_transform(data_features)\n",
    "# data_lables=scaler.fit_transform(data_lables)\n",
    "data_features=np.array(data_features)/10000000\n",
    "data_lables=np.array(data_lables)/10000000\n",
    "print(data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'data': array([[0.179  , 0.179  , 0.179  , ..., 0.179  , 0.179  , 0.179  ],\n",
      "       [0.308  , 0.308  , 0.308  , ..., 0.308  , 0.308  , 0.308  ],\n",
      "       [0.41   , 0.47   , 0.48   , ..., 0.553  , 0.553  , 0.553  ],\n",
      "       ...,\n",
      "       [0.22   , 0.28   , 0.32   , ..., 0.285  , 0.285  , 0.285  ],\n",
      "       [0.96   , 0.79   , 0.65   , ..., 0.78275, 0.78275, 0.78275],\n",
      "       [0.81   , 0.81   , 0.81   , ..., 0.81   , 0.81   , 0.81   ]]), b'lables': array([0.179, 0.308, 0.41 , ..., 0.32 , 0.665, 0.81 ])}\n"
     ]
    }
   ],
   "source": [
    "#处理原始数据\n",
    "data_obj={\n",
    "    b'data':data_features,\n",
    "    b'lables':data_lables\n",
    "}\n",
    "print(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# 定义数据格式 4*4*1，np.zeros创建空矩阵\n",
    "\n",
    "blank_image= np.zeros((len(data_obj[b'data']),4,4,1), np.float64) \n",
    "print(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向空矩阵中填充数据\n",
    "#print(np.array(data_obj[b'data'][1][0:16]).reshape(4,4))\n",
    "#print(blank_image[1][0:1,0:1,0:1])\n",
    "# print(blank_image[1][0:2,0:2])\n",
    "# print(blank_image[1][0:2,0:2,0])\n",
    "#串联所有通道为一维数组，blank_image[i][:,:,0]，取第1个通道的全部值\n",
    "\n",
    "for i in range(len(data_obj[b'data'])):\n",
    "    blank_image[i][:,:,0]=np.array(data_obj[b'data'][i][0:16]).reshape(4,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'data': array([[0.179  , 0.179  , 0.179  , ..., 0.179  , 0.179  , 0.179  ],\n",
      "       [0.308  , 0.308  , 0.308  , ..., 0.308  , 0.308  , 0.308  ],\n",
      "       [0.41   , 0.47   , 0.48   , ..., 0.553  , 0.553  , 0.553  ],\n",
      "       ...,\n",
      "       [0.22   , 0.28   , 0.32   , ..., 0.285  , 0.285  , 0.285  ],\n",
      "       [0.96   , 0.79   , 0.65   , ..., 0.78275, 0.78275, 0.78275],\n",
      "       [0.81   , 0.81   , 0.81   , ..., 0.81   , 0.81   , 0.81   ]]), b'lables': array([0.179, 0.308, 0.41 , ..., 0.32 , 0.665, 0.81 ])}\n"
     ]
    }
   ],
   "source": [
    "data_obj[b'lables']=np.array(data_obj[b'lables'])\n",
    "print(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "1901\n",
      "2100\n",
      "1901\n"
     ]
    }
   ],
   "source": [
    "#划分训练测试集\n",
    "X_train=blank_image[:2100]\n",
    "X_test=blank_image[2100:]\n",
    "y_train=data_obj[b'lables'][:2100]\n",
    "y_test=data_obj[b'lables'][2100:]\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(X_test, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2100, 4, 4, 1)\n",
      "2100 train samples\n",
      "1901 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 4, 1)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(4, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(1, kernel_size=(3, 3),padding='same', activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        #layers.Dropout(0.5),#避免过拟合\n",
    "        layers.Dense(1,activation='linear')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 4)           580       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 1)           37        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 794\n",
      "Trainable params: 794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2127 - accuracy: 0.0000e+00 - val_loss: 0.2695 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13acf0780>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1,verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09544708579778671\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29504576]\n",
      " [0.35537782]\n",
      " [0.365847  ]\n",
      " ...\n",
      " [0.27740356]\n",
      " [0.31962666]\n",
      " [0.36283135]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52  0.6   0.59  ... 0.32  0.665 0.81 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'conv2d/Relu:0' shape=(None, 4, 4, 16) dtype=float32>, <tf.Tensor 'conv2d_1/Relu:0' shape=(None, 4, 4, 4) dtype=float32>, <tf.Tensor 'conv2d_2/Relu:0' shape=(None, 4, 4, 1) dtype=float32>, <tf.Tensor 'flatten/Reshape:0' shape=(None, 16) dtype=float32>, <tf.Tensor 'dense/BiasAdd:0' shape=(None, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x13ad6a2e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处为了获得纯卷积结果，但是这个卷积是不纯的，因为经过了很多次迭代，不是一次卷积的结果，但是考虑到精确度不足4%，忽略了，换成一次迭代也是一样：（\n",
    "#这个设计有点意思，把model拿过来再做一次，只为了得到某一层的卷积结果\n",
    "layer_model =tf.keras.Model(inputs=model.input, outputs=model.layers[4].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得全部输入的卷积结果\n",
    "feature=layer_model.predict(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "4001\n",
      "[[2672139.108181  ]\n",
      " [2853549.12281036]\n",
      " [3450033.96272659]\n",
      " ...\n",
      " [2774035.63261032]\n",
      " [3196266.59154892]\n",
      " [3628313.54141235]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "print(type(feature))\n",
    "print(len(feature))\n",
    "\n",
    "#此处解释了之前归一化为什么不用fit_transform，因为卷积结果还要还原\n",
    "feature=feature*10000000\n",
    "print(feature)\n",
    "\n",
    "#再进行归一化，因为用XGboost方法训练的时候是用fit_transform归一化的\n",
    "scaler = preprocessing.StandardScaler()\n",
    "feature=scaler.fit_transform(feature)\n",
    "\n",
    "\n",
    "#numpy.ndarray转换array，再利用array转换成dataFrame，存在.csv文件，是在愚钝只能用此蠢方法了\n",
    "data=[]\n",
    "for i in range(len(feature)):\n",
    "    data.append([])\n",
    "    data[i].append(feature[i][0])\n",
    "#print(data)\n",
    "dff=pd.DataFrame()\n",
    "dd=dff.append(data)\n",
    "dd.to_csv('round_price_predict.csv',index=False)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#另外一种方法获得卷积结果，殊途同归\n",
    "\n",
    "from keras import backend as K\n",
    "def get_output_function(model,output_layer_index):\n",
    "    vector_funcrion=K.function([model.layers[0].input],[model.layers[output_layer_index].output])\n",
    "\n",
    "    def inner(input_data):\n",
    "\n",
    "        vector=vector_funcrion([input_data])[0]\n",
    "\n",
    "        return vector\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature=get_output_function(model,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=get_feature(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5141655 ]\n",
      " [0.47961882]\n",
      " [0.6933762 ]\n",
      " ...\n",
      " [0.27971557]\n",
      " [0.7742141 ]\n",
      " [0.81685627]]\n"
     ]
    }
   ],
   "source": [
    "print(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
